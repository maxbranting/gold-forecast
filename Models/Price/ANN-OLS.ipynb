{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gold</th>\n",
       "      <th>CrudeOil</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>FTSE250</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-01-02</th>\n",
       "      <td>326.30</td>\n",
       "      <td>25.56</td>\n",
       "      <td>209.59</td>\n",
       "      <td>1417.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-03</th>\n",
       "      <td>326.75</td>\n",
       "      <td>26.00</td>\n",
       "      <td>210.88</td>\n",
       "      <td>1424.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-06</th>\n",
       "      <td>328.00</td>\n",
       "      <td>26.53</td>\n",
       "      <td>210.65</td>\n",
       "      <td>1430.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-07</th>\n",
       "      <td>330.00</td>\n",
       "      <td>25.85</td>\n",
       "      <td>213.80</td>\n",
       "      <td>1421.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-08</th>\n",
       "      <td>332.60</td>\n",
       "      <td>25.87</td>\n",
       "      <td>207.97</td>\n",
       "      <td>1408.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Gold  CrudeOil  S&P500  FTSE250\n",
       "date                                         \n",
       "1986-01-02  326.30     25.56  209.59  1417.26\n",
       "1986-01-03  326.75     26.00  210.88  1424.61\n",
       "1986-01-06  328.00     26.53  210.65  1430.96\n",
       "1986-01-07  330.00     25.85  213.80  1421.22\n",
       "1986-01-08  332.60     25.87  207.97  1408.79"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\Dokumenty\\GitHub\\gold-forecast\\data\\data_nominal_clean.csv', sep=';')\n",
    "df.set_index('date', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0].values\n",
    "y = df.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X.reshape(X.shape[0],1))\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 326.3 ,  326.75,  328.  , ..., 1857.3 , 1834.  , 1852.2 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.Sequential([\n",
    "  # Before TensorFlow 2.7.0\n",
    "  # tf.keras.layers.Dense(100), # add 100 dense neurons\n",
    "\n",
    "  ## After TensorFlow 2.7.0 ## \n",
    "  tf.keras.layers.Dense(100, input_shape=(None,1)), # add 100 dense neurons with input_shape defined (None, 1) = look at 1 sample at a time\n",
    "  tf.keras.layers.Dense(15), # add another layer with 10 neurons\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compile the model\n",
    "ann.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(), # use Adam instead of SGD\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "258/258 [==============================] - 2s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 2/20\n",
      "258/258 [==============================] - 0s 2ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 3/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 4/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 5/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 6/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 7/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 8/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 9/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 10/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 11/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 12/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 13/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 14/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 15/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 16/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 17/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 18/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 19/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n",
      "Epoch 20/20\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 4.4063 - accuracy: 1.2145e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x180b72b70a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(tf.expand_dims(X_train, axis=-1), # <- expand dimension on final axis \n",
    "            y_train, \n",
    "            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21f5697bda450ce0b26b1133c642395c1828fd8433dc23004486b6935951cd15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
